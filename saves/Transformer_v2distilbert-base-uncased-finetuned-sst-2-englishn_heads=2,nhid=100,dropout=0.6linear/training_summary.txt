Training summary
================
Presentation:
Model: Transformer_v2distilbert-base-uncased-finetuned-sst-2-englishn_heads=2,nhid=100,dropout=0.6linear
Timestamp: 2024-02-03 04:41:50.858669
Host: gpu5.enst.fr
================
Parameters:
Number of epochs: 120
Batch size: 128
Learning rate: 0.0001
================
Model Parameters:
Model name: distilbert-base-uncased-finetuned-sst-2-english
Number of parameters: 70402381
================
Hardware:
GPU found: NVIDIA A100-PCIE-40GB
GPU memory: 40338.312 MB 
================
Training time: 60235.37603139877
Best validation loss: 0.42057831012285674
Training loss mean over last 500 iterations: 0.0539205820527859
================
