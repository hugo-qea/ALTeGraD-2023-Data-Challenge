Training summary
================
Presentation:
Model: Transformer_v2distilbert-base-uncased-finetuned-sst-2-englishn_heads=2,nhid=100,dropout=0.6
Timestamp: 2024-02-01 23:59:28.664978
Host: gpu6.enst.fr
================
Parameters:
Number of epochs: 120
Batch size: 180
Learning rate: 0.0001
================
Model Parameters:
Model name: distilbert-base-uncased-finetuned-sst-2-english
Number of parameters: 70218948
================
Hardware:
GPU found: NVIDIA A100-PCIE-40GB
GPU memory: 40338.312 MB 
================
Training time: 44121.303324222565
Best validation loss: 0.46412725981913117
Training loss mean over last 500 iterations: 0.05077835344290361
================
